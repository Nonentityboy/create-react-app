import React, { useEffect, useRef, useState } from 'react';
import { Button } from 'antd-mobile';
import * as faceapi from 'face-api.js';
import { LeftOutline } from 'antd-mobile-icons';
import AvatarHeader from './AvatarHeader';
import SpeechToText from './SpeechToText';
import menuIcon from '../../assets/menu.svg';
import pauseIcon from '../../assets/pause.svg';
import startIcon from '../../assets/start.svg';
import backIcon from '../../assets/back.svg';
import './index.css';

const user = {
    avatar: 'https://raw.githubusercontent.com/Nonentityboy/PicGoToGitHub/master/1.png', // æ›¿æ¢ä¸ºå®é™…å¤´åƒ URL
    name: 'é¢œ',
    id: '18838292',
};

const audienceAvatars = [
    'https://raw.githubusercontent.com/Nonentityboy/PicGoToGitHub/master/1.png',
    'https://raw.githubusercontent.com/Nonentityboy/PicGoToGitHub/master/1.png',
    'https://raw.githubusercontent.com/Nonentityboy/PicGoToGitHub/master/1.png',
    // å…¶ä»–è§‚ä¼—å¤´åƒ URL
];

const audienceCount = 2000;

function FaceDetectionVideo({ messages }) {
    const [modelsLoaded, setModelsLoaded] = useState(false);
    // æ§åˆ¶å¼€å¯å…³é—­ç›´æ’­
    const [captureVideo, setCaptureVideo] = useState(false);
    const videoRef = useRef();
    const canvasRef = useRef();
    const videoHeight = 480;
    const videoWidth = 640;

    // æ–°å¢çŠ¶æ€å’Œäº‹ä»¶å¤„ç†
    const [isPaused, setIsPaused] = useState(false);

    const handlePause = () => {
        setIsPaused(true);
        videoRef.current.pause(); // æš‚åœè§†é¢‘æ’­æ”¾
    };

    const handleResume = () => {
        setIsPaused(false);
        videoRef.current.play(); // æ¢å¤è§†é¢‘æ’­æ”¾
    };

    useEffect(() => {
        const loadModels = async () => {
            const MODEL_URL = process.env.PUBLIC_URL + '/models';
            await Promise.all([
                faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
                faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
                faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),
                faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),
            ]);
            setModelsLoaded(true);
        };
        loadModels();
    }, []);

    const startVideo = () => {
        setCaptureVideo(true);
        navigator.mediaDevices
            .getUserMedia({ video: { width: 300 } })
            .then(stream => {
                const video = videoRef.current;
                video.srcObject = stream;
                video.play();
            })
            .catch(err => {
                console.error("error:", err);
            });
    };

    const handleVideoOnPlay = () => {
        setInterval(async () => {
            if (canvasRef.current) {
                const displaySize = { width: videoRef.current.offsetWidth, height: videoRef.current.offsetHeight };
                faceapi.matchDimensions(canvasRef.current, displaySize);

                const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceExpressions();
                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                const ctx = canvasRef.current.getContext('2d');
                ctx.clearRect(0, 0, displaySize.width, displaySize.height);

                resizedDetections.forEach(detection => {
                    const { x, y, width } = detection.detection.box;
                    ctx.font = "36px Arial";
                    ctx.fillStyle = "red";
                    ctx.textAlign = "center";
                    ctx.fillText("æˆ‘è¦å½“ç½‘çº¢", x + width / 2, y - 10);

                });
            }
        }, 1000);
    };


    const closeWebcam = () => {
        videoRef.current.pause();
        videoRef.current.srcObject.getTracks()[0].stop();
        setCaptureVideo(false);
    };

    const handleTranscriptChange = (text) => {
        console.log({ text })
        // addMessage({ name: user.name, text, emoji: 'ğŸ¤' });
    };

    return (
        <div className="face-detection-container">
            {captureVideo && modelsLoaded && (
                <div className="video-wrapper">
                    <AvatarHeader
                        user={user}
                        audienceCount={audienceCount}
                        audienceAvatars={audienceAvatars}
                    />
                    {/* åº•éƒ¨æ•ˆæœ */}
                    <div className="bottom-left-container">
                        <div className="top-overlay">
                            âš ï¸ç›´æ’­æå€¡ç»¿è‰²ç›´æ’­ï¼Œä¸¥ç¦æ¶‰åŠæ”¿æ²»ã€æ¶‰æã€æ¶‰é»„ã€èšä¼—é—¹äº‹ã€è¿”ç°ç­‰å†…å®¹ï¼Œç½‘è­¦24å°æ—¶å·¡æŸ¥ã€‚
                    </div>
                        <div className="live-topic">æœ¬åœºç›´æ’­ä¸»é¢˜æ˜¯ã€ä»å¿ƒå¼€å§‹ã€‘</div>
                    </div>


                    <video ref={videoRef} height={videoHeight} width={videoWidth} playsInline controls={false} onPlay={handleVideoOnPlay} className="video-stream" />
                    <canvas ref={canvasRef} className="video-canvas" />

                    {/* è¯­éŸ³è½¬æ–‡å­—åŠŸèƒ½ */}

                    <SpeechToText
                        onTranscriptChange={handleTranscriptChange}
                        isPaused={isPaused}
                    />

                    {/* AI Agent Messages */}
                    <div className="ai-messages">
                        {messages.map((message) => (
                            <div key={message.id} className="message-item">
                                <span className="message-name">{message.name}:</span>
                                <span>{message.text}</span>
                            </div>
                        ))}
                    </div>
                </div>
            )}
            {captureVideo && modelsLoaded ? (
                <div className="operate-container">
                    <div className={`overlay ${isPaused ? 'active' : ''}`}></div>
                    <img src={menuIcon} alt="Menu Icon" className="button-icon" />
                    <img src={backIcon} onClick={closeWebcam} className="button-icon back-button" alt="Back Icon" />
                    <img
                        src={isPaused ? startIcon : pauseIcon}
                        onClick={isPaused ? handleResume : handlePause}
                        className="button-icon pause-button"
                        alt={isPaused ? "Start Icon" : "Pause Icon"}
                    />
                    {/* é¢„ç•™å…¶ä»–æ“ä½œæŒ‰é’® */}
                </div>
            ) : (
                    <div className="setup-container">
                        <div className="setup-title">å®šåˆ¶æ‚¨çš„ä¸»æ’­äººè®¾ï¼š</div>
                        <img src="https://raw.githubusercontent.com/Nonentityboy/PicGoToGitHub/master/first.jpg" alt="ç›´æ’­å›¾æ ‡" className="setup-image" />
                        <Button color='primary' fill='solid' onClick={startVideo}>ä¸€é”®ç›´æ’­</Button>
                    </div>
                )}
        </div>
    );
}

export default FaceDetectionVideo;
